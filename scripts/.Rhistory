"524",
"525",
"525",
"526",
"526",
"527",
"527"
),
cond = c(
"C",
"D",
"C",
"D",
"C",
"D",
"C",
"D",
"C",
"D",
"C",
"D",
"C",
"D"
)
)
test_sample
std_curve <- tibble(
std1 = c(
0.233,
0.271,
0.352,
0.352,
0.495,
0.472,
0.44
),
std2 = c(
0.478,
0.416,
0.464,
0.540,
0.595,
0.432,
0.482
)
) %>%
rowwise() %>%
mutate(
std_mean = mean(c(std1, std2)),
b0 = b0,
tad = tad,
std_b_b0 = (std_mean / tad)
)
std_curve
four_pl <- function(params, x) {
A <- params[1] # max asymptote (b0)
B <- params[2] # hill slope
C <- params[3] # inflection point (e50)
D <- params[4] # min asymptote
y_predicted <- D + (A - D) / (1 + (x / C)^B)
return(y_predicted)
}
inverse_four_pl <- function(params, y) {
A <- params[1] # Max asymptote
B <- params[2] # Hill Slope
C <- params[3] # Inflection Point
D <- params[4] # Min asymptote
# The inverse 4PL equation
x_predicted <- C * (((A - D) / (y - D)) - 1)^(1 / B)
return(x_predicted)
}
sse_4pl <- function(params, x_obs, y_obs) {
# Get the predicted y-values from our 4PL model
y_predicted <- four_pl(params, x_obs)
# Calculate the sum of the squared differences (errors)
error <- sum((y_obs - y_predicted)^2)
return(error)
}
initial_params <- c(
A = 1, # Guess A is the max observed OD
B = -1, # Guess B is -1 for a decreasing slope
C = median(concentration[concentration > 0]), # Guess C is the middle concentration
D = 0 # Guess D is the min observed OD
)
fit <- optim(
par = initial_params,
fn = sse_4pl,
x_obs = log(concentration[concentration > 0]),
y_obs = std_curve$std_b_b0[concentration > 0],
method = "BFGS"
)
optimized_params <- fit$par
preds <- four_pl(optimized_params, seq(6.1, 600, 0.01))
dat <- tibble(
x = concentration[concentration > 0],
y = four_pl(optimized_params, concentration[concentration > 0])
)
dat
calculated_conc <- inverse_four_pl(optimized_params, std_curve$std_b_b0)
percent_recovery <- (calculated_conc / concentration) * 100
sample_concentrations <- inverse_four_pl(optimized_params, test_sample$OD)
sample_concentrations
percent_recovery
pacman::p_load(
tidyverse,
ggplot2
)
nsb <- mean(c(0.195, 0.241))
tad <- mean(c(0.44, 0.482))
concentration <- c(600, 240, 96, 38.4, 15.4, 6.1, 0)
test_sample <- tibble(
OD1 = c(
0.180,
0.188,
0.228,
0.216,
0.225,
0.169,
0.210,
0.188,
0.254,
0.203,
0.245,
0.237,
0.380,
0.338
),
OD2 = c(
0.209,
0.171,
0.223,
0.226,
0.255,
0.293,
0.207,
0.224,
0.215,
0.203,
0.390,
0.312,
0.387,
0.264
)
) %>%
rowwise() %>%
mutate(
OD_mean = mean(c(OD1, OD2)),
b0 = tad,
OD = (OD_mean / tad)
) %>%
ungroup() %>%
mutate(
id = c(
"521",
"521",
"522",
"522",
"523",
"523",
"524",
"524",
"525",
"525",
"526",
"526",
"527",
"527"
),
cond = c(
"C",
"D",
"C",
"D",
"C",
"D",
"C",
"D",
"C",
"D",
"C",
"D",
"C",
"D"
)
)
test_sample
std_curve <- tibble(
std1 = c(
0.233,
0.271,
0.352,
0.352,
0.495,
0.472,
0.44
),
std2 = c(
0.478,
0.416,
0.464,
0.540,
0.595,
0.432,
0.482
)
) %>%
rowwise() %>%
mutate(
std_mean = mean(c(std1, std2)),
b0 = b0,
tad = tad,
std_b_b0 = (std_mean / tad)
)
std_curve
four_pl <- function(params, x) {
A <- params[1] # max asymptote (b0)
B <- params[2] # hill slope
C <- params[3] # inflection point (e50)
D <- params[4] # min asymptote
y_predicted <- D + (A - D) / (1 + (x / C)^B)
return(y_predicted)
}
inverse_four_pl <- function(params, y) {
A <- params[1] # Max asymptote
B <- params[2] # Hill Slope
C <- params[3] # Inflection Point
D <- params[4] # Min asymptote
# The inverse 4PL equation
x_predicted <- C * (((A - D) / (y - D)) - 1)^(1 / B)
return(x_predicted)
}
sse_4pl <- function(params, x_obs, y_obs) {
# Get the predicted y-values from our 4PL model
y_predicted <- four_pl(params, x_obs)
# Calculate the sum of the squared differences (errors)
error <- sum((y_obs - y_predicted)^2)
return(error)
}
initial_params <- c(
A = 1, # Guess A is the max observed OD
B = -1, # Guess B is -1 for a decreasing slope
C = median(concentration[concentration > 0]), # Guess C is the middle concentration
D = 0 # Guess D is the min observed OD
)
fit <- optim(
par = initial_params,
fn = sse_4pl,
x_obs = log(concentration[concentration > 0]),
y_obs = std_curve$std_b_b0[concentration > 0],
method = "BFGS"
)
optimized_params <- fit$par
sample_concentrations <- inverse_four_pl(optimized_params, test_sample$OD)
sample_concentrations
ggplot(data = std_curve, aes(x = concentration, y = std_b_b0)) +
geom_point(color = "blue", size = 3, aes(y = std_b_b0)) +
stat_function(fun = function(x) four_pl(optimized_params, log(x)), color = "red", size = 1) +
scale_x_log10(breaks = c(1, 10, 100, 1000)) + # Use a logarithmic x-axis scale
labs(
title = "Corrected 4-Parameter Logistic Curve Fit",
x = "Concentration (pg/mL) [Log Scale]",
y = "Normalized OD (B/B₀)"
) +
theme_minimal()
sample_concentrations <- inverse_four_pl(optimized_params, test_sample$OD)
exp(sample_concentrations)
ggplot(data = std_curve, aes(x = concentration, y = std_b_b0)) +
geom_point(color = "blue", size = 3, aes(y = std_b_b0)) +
stat_function(fun = function(x) four_pl(optimized_params, (x)), color = "red", size = 1) +
scale_x_log10(breaks = c(1, 10, 100, 1000)) + # Use a logarithmic x-axis scale
labs(
title = "Corrected 4-Parameter Logistic Curve Fit",
x = "Concentration (pg/mL) [Log Scale]",
y = "Normalized OD (B/B₀)"
) +
theme_minimal()
pacman::p_load(
tidyverse,
ggplot2,
httr,
jsonlite
)
setwd(this.path::here())
hashrate_url <- "https://api.blockchain.info/charts/hash-rate?timespan=all&format=json"
btc_url <- "https://api.blockchain.info/charts/market-price?timespan=all&format=json"
trans_url <- "https://api.blockchain.info/charts/n-transactions?timespan=all&format=json"
fees_url <- "https://api.blockchain.info/charts/transaction-fees-usd?timespan=all&format=json"
url_list <- list(
hashrate_url,
btc_url,
trans_url,
fees_url
)
data_names <- c(
"hashrate",
"btc_price",
"transactions",
"fees"
)
data <- url_list %>%
imap(
., function(X, idx) {
response <- GET(X)
json_content <- content(response, as = "text")
data_list <- fromJSON(json_content)
price_df <- tibble(data_list$values) %>%
mutate(class = data_names[idx])
return(price_df)
}
)
# fred data
dff <- read_csv("DFF.csv") %>%
mutate(
observation_date = as.numeric(as.POSIXct(observation_date, tz = "UTC")),
class = "dff"
) %>%
rename(
x = observation_date,
y = DFF
)
walcl <- read_csv("WALCL.csv") %>%
mutate(
observation_date = as.numeric(as.POSIXct(observation_date, tz = "UTC")),
class = "walcl"
) %>%
rename(
x = observation_date,
y = WALCL
)
l_n <- 1
data_full <- bind_rows(data, dff, walcl) %>%
pivot_wider(
names_from = class,
values_from = y
) %>%
arrange(x) %>%
mutate(
price_int = zoo::na.approx(btc_price, rule = 2),
hashrate_int = zoo::na.approx(hashrate, rule = 2),
transactions_int = zoo::na.approx(transactions, rule = 2),
fees_int = zoo::na.approx(fees, rule = 2),
dff_int = zoo::na.approx(dff, rule = 2),
walcl_int = zoo::na.approx(walcl, rule = 2),
price_lag = lag(price_int, n = l_n),
hashrate_lag = lag(hashrate_int, n = l_n),
transactions_lag = lag(transactions_int, n = l_n),
fees_lag = lag(fees_int, n = l_n),
dff_lag = lag(dff_int, n = l_n),
walcl_lag = lag(walcl_int, n = l_n),
log_return = log(price_int) - log(lag(price_int, n = 1)),
return_bin = if_else(exp(log_return) - 1 > 0, 1, 0)
) %>%
drop_na(log_return) %>%
filter(log_return < Inf)
data_mdl <- lm(
data = data_full,
log_return ~ log(hashrate_lag + 1) *
log(transactions_lag + 1) *
log(fees_lag + 1) *
log(walcl_lag + 1) *
log(dff_lag + 1)
)
summary(data_mdl)
data_mdl <- glm(
data = data_full,
return_bin ~ log(hashrate_lag + 1) *
log(transactions_lag + 1) *
log(fees_lag + 1) *
log(walcl_lag + 1) *
log(dff_lag + 1),
family = binomial(link = "logit")
)
summary(data_mdl)
probabilities <- predict(data_mdl, type = "response")
predicted_classes <- ifelse(probabilities > 0.5, 1, 0)
conf_matrix <- table(Predicted = predicted_classes, Actual = data_full$return_bin)
conf_matrix
accuracy <- (conf_matrix[1, 1] + conf_matrix[2, 2]) / sum(conf_matrix)
print(paste("Accuracy:", accuracy))
pacman::p_load(
tidyverse,
ggplot2,
httr,
jsonlite,
randomForest
)
rf_mdl <- randomForest(
data = data_full,
return_bin ~ log(hashrate_lag + 1) *
log(transactions_lag + 1) *
log(fees_lag + 1) *
log(walcl_lag + 1) *
log(dff_lag + 1)
)
data_full
data_full$hashrate_lag
data_full$hashrate_lag
?randomForest
rf_mdl <- randomForest(
data = data_full,
return_bin ~ log(hashrate_lag + 1) +
log(transactions_lag + 1) +
log(fees_lag + 1) +
log(walcl_lag + 1) +
log(dff_lag + 1)
)
data_full$hashrate_lag
rf_mdl <- randomForest(
return_bin ~ log(hashrate_lag + 1) +
log(transactions_lag + 1) +
log(fees_lag + 1) +
log(walcl_lag + 1) +
log(dff_lag + 1),
data = data_full
)
data_full$hashrate_lag
randomForest(
data = data_full
return_bin ~ hashrate_lag
randomForest(
data = data_full,
return_bin ~ hashrate_lag
)
randomForest(
data = data_full,
return_bin ~ log(hashrate_lag)
)
rf_data <- data_full %>%
mutate(
log_hashrate_lag = log(hashrate_lag + 1),
log_transactions_lag = log(transactions_lag + 1),
log_fees_lag = log(fees_lag + 1),
log_walcl_lag = log(walcl_lag + 1),
log_dff_lag = log(dff_lag + 1)
)
rf_mdl <- randomForest(
return_bin ~ log_hashrate_lag +
log_transactions_lag +
log_fees_lag +
log_walcl_lag +
log_dff_lag,
data = rf_data
)
rf_data <- data_full %>%
mutate(
return_bin = as.factor(return_bin),
log_hashrate_lag = log(hashrate_lag + 1),
log_transactions_lag = log(transactions_lag + 1),
log_fees_lag = log(fees_lag + 1),
log_walcl_lag = log(walcl_lag + 1),
log_dff_lag = log(dff_lag + 1)
)
rf_mdl <- randomForest(
return_bin ~ log_hashrate_lag +
log_transactions_lag +
log_fees_lag +
log_walcl_lag +
log_dff_lag,
data = rf_data
)
rf_mdl
100-24.47
rf_data
tail(rf_data, 1)
View(rf_data)
rf_data <- data_full %>%
mutate(
x = lubridate::as_date(x),
return_bin = as.factor(return_bin),
log_hashrate_lag = log(hashrate_lag + 1),
log_transactions_lag = log(transactions_lag + 1),
log_fees_lag = log(fees_lag + 1),
log_walcl_lag = log(walcl_lag + 1),
log_dff_lag = log(dff_lag + 1)
)
rf_data <- data_full %>%
mutate(
return_bin = as.factor(return_bin),
log_hashrate_lag = log(hashrate_lag + 1),
log_transactions_lag = log(transactions_lag + 1),
log_fees_lag = log(fees_lag + 1),
log_walcl_lag = log(walcl_lag + 1),
log_dff_lag = log(dff_lag + 1)
)
View(data_full)
rf_data <- data_full %>%
mutate(
date = as_datetime(x),
return_bin = as.factor(return_bin),
log_hashrate_lag = log(hashrate_lag + 1),
log_transactions_lag = log(transactions_lag + 1),
log_fees_lag = log(fees_lag + 1),
log_walcl_lag = log(walcl_lag + 1),
log_dff_lag = log(dff_lag + 1)
)
rf_data <- data_full %>%
mutate(
date = as_datetime(x),
return_bin = as.factor(return_bin),
log_hashrate_lag = log(hashrate_lag + 1),
log_transactions_lag = log(transactions_lag + 1),
log_fees_lag = log(fees_lag + 1),
log_walcl_lag = log(walcl_lag + 1),
log_dff_lag = log(dff_lag + 1)
)
rf_data
View(rf_data)
pred_data <- rf_data %>%
mutate(
.pred = predict(rf_mdl)
)
View(pred_data)
